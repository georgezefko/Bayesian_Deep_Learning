{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "import wandb\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzefko\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/zefko/Bayesian%20DL/runs/tsh8lx5m\" target=\"_blank\">STN_trial</a></strong> to <a href=\"https://wandb.ai/zefko/Bayesian%20DL\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/zefko/Bayesian%20DL/runs/tsh8lx5m?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4addd62350>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Bayesian DL\", name = 'STN_trial', entity=\"zefko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 100,\n",
    "  \"batch_size\": 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistRandomPlacement(Dataset):\n",
    "\n",
    "  def __init__(self, crop_size, digits,mode,download=True):\n",
    "\n",
    "    self.datasets = []\n",
    "    self.cropsize = crop_size\n",
    "    self.download = download\n",
    "    self.digits = digits\n",
    "    self.mode = mode\n",
    "\n",
    "    # False (test) or True (train,val)\n",
    "    trainingset = self.mode in ['train', 'val']\n",
    "\n",
    "    self.datasets.append(datasets.MNIST('/content/',\n",
    "                        transform=transforms.Compose([\n",
    "                        transforms.ToTensor()]),\n",
    "                        train=trainingset,\n",
    "                        download=self.download))\n",
    "\n",
    "    # self.datasets.append(datasets.KMNIST(opt.dataroot,\n",
    "    #                     transform=transforms.Compose([\n",
    "    #                     transforms.ToTensor()]),\n",
    "    #                     train=trainingset,\n",
    "    #                     download=opt.download))\n",
    "\n",
    "    self.num_images = self.digits\n",
    "\n",
    "  def __len__(self):\n",
    "    return min([self.datasets[0].__len__() for i in range(self.num_images)])\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    im = torch.zeros((1, 96, 96), dtype=torch.float)\n",
    "\n",
    "    used_positions, target = [], ''\n",
    "    for i in range(self.num_images):\n",
    "      while True:\n",
    "        x = np.random.randint(0, 96 - 32)\n",
    "        if len(used_positions) == 0 or abs(used_positions[0][0] - x) > 32:\n",
    "          break\n",
    "      while True:\n",
    "        y = np.random.randint(0, 96 - 32)\n",
    "        if len(used_positions) == 0 or abs(used_positions[0][1] - y) > 32:\n",
    "          break\n",
    "\n",
    "      im1, target1 = self.datasets[i].__getitem__((idx) * (i + 1) % self.datasets[i].__len__())\n",
    "\n",
    "      c, w, h = im1.shape\n",
    "\n",
    "      im[:, y:y + h, x:x + w] = im1.type(torch.float)\n",
    "      #print('created image', im.shape, 'x:', x, 'y:', y)\n",
    "\n",
    "      target += str(target1)\n",
    "\n",
    "      transform = transforms.Compose(\n",
    "      [transforms.ToPILImage(),transforms.Resize(self.cropsize), transforms.ToTensor(),#, transforms.RandomRotation(degrees=(0,180))\n",
    "      transforms.Normalize((0.1307,), (0.3081,))])\n",
    "      im = transform(im)\n",
    "\n",
    "      \n",
    "\n",
    "      return im,int(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mnist = MnistRandomPlacement(28,10,'train',True)\n",
    "test_mnist = MnistRandomPlacement(28,10,'test',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 28, 28]) 5\n",
      "1 torch.Size([1, 28, 28]) 0\n",
      "2 torch.Size([1, 28, 28]) 4\n",
      "3 torch.Size([1, 28, 28]) 1\n",
      "4 torch.Size([1, 28, 28]) 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(train_mnist.datasets[0])):\n",
    "    image,label = train_mnist[i]\n",
    "\n",
    "    print(i, image.shape, label)\n",
    "\n",
    "    ax = plt.subplot(1, 5, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    ax.imshow(image[0,:,:].numpy())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if i == 4:\n",
    "        plt.show()\n",
    "        break\n",
    "wandb.log({'MNIST examples': wandb.Image(ax)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training dataset\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST(root='.', train=True, download=True,\n",
    "#                    transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ])), batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# Training dataset random placement\n",
    "train_loader = torch.utils.data.DataLoader(train_mnist, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "# Test dataset\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST(root='.', train=False, transform=transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.1307,), (0.3081,))\n",
    "#     ])), batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "# Test dataset random placement mnist\n",
    "test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[1].squeeze()\n",
    "label = train_labels[1]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_dt = wandb.Table(columns=[\"id\", \"image\", \"label\", \"split\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    label = train_labels[i]\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(train_features[i][0], cmap='gray')\n",
    "    plt.title(label)\n",
    "    #print(f\"Label: {label}\")\n",
    "    preview_dt.add_data(i,wandb.Image(train_features[i]),label,'train')\n",
    "wandb.log({'Train Input':preview_dt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3928... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f363289e9740bab2f7688a03ac68ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.02MB of 0.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 1805, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 1988, in _on_finish\n",
      "    self._poll_exit_response = self._wait_for_finish()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 1935, in _wait_for_finish\n",
      "    self._on_finish_progress(pusher_stats, done)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 1923, in _on_finish_progress\n",
      "    self._pusher_print_status(progress, done=done)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 1899, in _pusher_print_status\n",
      "    self._jupyter_progress.close()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/lib/ipython.py\", line 97, in close\n",
      "    self._widget.close()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipywidgets/widgets/widget.py\", line 469, in close\n",
      "    self.comm.close()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/comm/comm.py\", line 116, in close\n",
      "    self.kernel.comm_manager.unregister_comm(self)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/comm/manager.py\", line 56, in unregister_comm\n",
      "    comm = self.comms.pop(comm.comm_id)\n",
      "KeyError: '93f363289e9740bab2f7688a03ac68ad'\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #self.conv3 = nn.Conv2d(20, 30, kernel_size=5)\n",
    "        #self.conv3_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50) #original\n",
    "        #self.fc1 = nn.Linear(16820, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "#apply laplace to the last linera layer for the first attempt\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),#original\n",
    "            #nn.Linear(10 * 28* 28, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        #print('x',x.size())\n",
    "        xs = self.localization(x)\n",
    "\n",
    "        #print('xs',xs.size())\n",
    "        xs = xs.view(-1, 10 * 3 * 3) #original\n",
    "        #xs = xs.view(-1, 10 * 28 * 28)\n",
    "\n",
    "        #print('xs view',xs.size())\n",
    "        theta = self.fc_loc(xs)\n",
    "\n",
    "        #print('theta before view',theta.shape)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        #print('theta',theta.shape)\n",
    "        #print('size',x.size())\n",
    "\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size(),align_corners =True)\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #print('input',x.size())\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        #print('transform',x.size())\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        #print('forward1',x.size())\n",
    "\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #print('forward2',x.size())\n",
    "\n",
    "        #x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
    "        #print('forward2+',x.size())\n",
    "\n",
    "        x = x.view(-1, 320) #original\n",
    "        #x = x.view(-1, 16820)\n",
    "\n",
    "        #print('forward3',x.size())\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print('forward4',x.size())\n",
    "\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        #print('forward5',x.size())\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        #print('forward6',x.size())\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    wandb.watch(model, optimizer,log=\"all\", log_freq=10)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            wandb.log({\"epoch\": epoch, \"loss\": loss.item()})\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        wandb.log({\"test loss\": test_loss})\n",
    "\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_np(inp):\n",
    "    \"\"\"Convert a Tensor to numpy image.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:4004: UserWarning:\n",
      "\n",
      "Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306885\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.307741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning:\n",
      "\n",
      "size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2997, Accuracy: 1439/10000 (14%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.299720\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.300446\n",
      "\n",
      "Test set: Average loss: 2.2913, Accuracy: 1561/10000 (16%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.287234\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.284089\n",
      "\n",
      "Test set: Average loss: 2.2578, Accuracy: 1782/10000 (18%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.268181\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.228454\n",
      "\n",
      "Test set: Average loss: 2.1956, Accuracy: 1947/10000 (19%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.133359\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.169870\n",
      "\n",
      "Test set: Average loss: 2.1461, Accuracy: 2096/10000 (21%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.171651\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.113768\n",
      "\n",
      "Test set: Average loss: 2.0961, Accuracy: 2198/10000 (22%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.104756\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.045749\n",
      "\n",
      "Test set: Average loss: 2.0208, Accuracy: 2375/10000 (24%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.102748\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.017626\n",
      "\n",
      "Test set: Average loss: 1.9810, Accuracy: 2361/10000 (24%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.080063\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.186505\n",
      "\n",
      "Test set: Average loss: 1.9312, Accuracy: 2613/10000 (26%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.993711\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.048718\n",
      "\n",
      "Test set: Average loss: 1.8411, Accuracy: 2989/10000 (30%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 1.976205\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 1.714423\n",
      "\n",
      "Test set: Average loss: 1.7486, Accuracy: 3331/10000 (33%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 1.905603\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 1.944880\n",
      "\n",
      "Test set: Average loss: 1.6445, Accuracy: 3552/10000 (36%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 1.814698\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 1.643364\n",
      "\n",
      "Test set: Average loss: 1.5758, Accuracy: 3780/10000 (38%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 1.514639\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 1.606167\n",
      "\n",
      "Test set: Average loss: 1.5995, Accuracy: 3953/10000 (40%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 1.786065\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 1.709171\n",
      "\n",
      "Test set: Average loss: 1.4081, Accuracy: 5108/10000 (51%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 1.618745\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 1.436280\n",
      "\n",
      "Test set: Average loss: 1.2931, Accuracy: 5564/10000 (56%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 1.342830\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 1.393764\n",
      "\n",
      "Test set: Average loss: 1.3461, Accuracy: 5447/10000 (54%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 1.681072\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 1.107394\n",
      "\n",
      "Test set: Average loss: 1.0149, Accuracy: 6723/10000 (67%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 1.148275\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 1.093628\n",
      "\n",
      "Test set: Average loss: 0.8375, Accuracy: 7512/10000 (75%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 1.064854\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.867631\n",
      "\n",
      "Test set: Average loss: 0.7491, Accuracy: 7709/10000 (77%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 1.032625\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 1.043231\n",
      "\n",
      "Test set: Average loss: 0.6584, Accuracy: 7961/10000 (80%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 1.363205\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.659405\n",
      "\n",
      "Test set: Average loss: 0.8295, Accuracy: 7312/10000 (73%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 1.424728\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.865257\n",
      "\n",
      "Test set: Average loss: 0.4721, Accuracy: 8681/10000 (87%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.742816\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.904777\n",
      "\n",
      "Test set: Average loss: 0.4201, Accuracy: 8790/10000 (88%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.431579\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.565528\n",
      "\n",
      "Test set: Average loss: 0.5111, Accuracy: 8497/10000 (85%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.707189\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 0.530510\n",
      "\n",
      "Test set: Average loss: 0.4548, Accuracy: 8760/10000 (88%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.604260\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 1.004811\n",
      "\n",
      "Test set: Average loss: 0.4176, Accuracy: 8811/10000 (88%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.554169\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 0.736967\n",
      "\n",
      "Test set: Average loss: 0.5585, Accuracy: 8314/10000 (83%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.772247\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 0.578643\n",
      "\n",
      "Test set: Average loss: 0.4946, Accuracy: 8487/10000 (85%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.782214\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 0.989217\n",
      "\n",
      "Test set: Average loss: 0.5422, Accuracy: 8285/10000 (83%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 1.037729\n",
      "Train Epoch: 31 [32000/60000 (53%)]\tLoss: 0.510116\n",
      "\n",
      "Test set: Average loss: 0.4360, Accuracy: 8696/10000 (87%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 1.187025\n",
      "Train Epoch: 32 [32000/60000 (53%)]\tLoss: 0.666798\n",
      "\n",
      "Test set: Average loss: 0.3433, Accuracy: 9012/10000 (90%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.628394\n",
      "Train Epoch: 33 [32000/60000 (53%)]\tLoss: 0.739571\n",
      "\n",
      "Test set: Average loss: 0.4323, Accuracy: 8665/10000 (87%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.525968\n",
      "Train Epoch: 34 [32000/60000 (53%)]\tLoss: 0.488148\n",
      "\n",
      "Test set: Average loss: 0.3386, Accuracy: 9057/10000 (91%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.641522\n",
      "Train Epoch: 35 [32000/60000 (53%)]\tLoss: 0.482309\n",
      "\n",
      "Test set: Average loss: 0.3051, Accuracy: 9100/10000 (91%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.570920\n",
      "Train Epoch: 36 [32000/60000 (53%)]\tLoss: 0.825839\n",
      "\n",
      "Test set: Average loss: 0.3042, Accuracy: 9139/10000 (91%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.569839\n",
      "Train Epoch: 37 [32000/60000 (53%)]\tLoss: 0.588277\n",
      "\n",
      "Test set: Average loss: 0.3006, Accuracy: 9147/10000 (91%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.663293\n",
      "Train Epoch: 38 [32000/60000 (53%)]\tLoss: 0.364121\n",
      "\n",
      "Test set: Average loss: 0.3185, Accuracy: 9059/10000 (91%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.569396\n",
      "Train Epoch: 39 [32000/60000 (53%)]\tLoss: 0.645748\n",
      "\n",
      "Test set: Average loss: 0.4481, Accuracy: 8712/10000 (87%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.701559\n",
      "Train Epoch: 40 [32000/60000 (53%)]\tLoss: 0.261595\n",
      "\n",
      "Test set: Average loss: 0.3201, Accuracy: 9120/10000 (91%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.482581\n",
      "Train Epoch: 41 [32000/60000 (53%)]\tLoss: 0.638463\n",
      "\n",
      "Test set: Average loss: 0.3407, Accuracy: 9031/10000 (90%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.631761\n",
      "Train Epoch: 42 [32000/60000 (53%)]\tLoss: 0.375874\n",
      "\n",
      "Test set: Average loss: 0.3481, Accuracy: 8958/10000 (90%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.646926\n",
      "Train Epoch: 43 [32000/60000 (53%)]\tLoss: 0.758654\n",
      "\n",
      "Test set: Average loss: 0.3182, Accuracy: 9105/10000 (91%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.414463\n",
      "Train Epoch: 44 [32000/60000 (53%)]\tLoss: 0.646148\n",
      "\n",
      "Test set: Average loss: 0.2501, Accuracy: 9280/10000 (93%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.565218\n",
      "Train Epoch: 45 [32000/60000 (53%)]\tLoss: 0.393873\n",
      "\n",
      "Test set: Average loss: 0.2420, Accuracy: 9292/10000 (93%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.456528\n",
      "Train Epoch: 46 [32000/60000 (53%)]\tLoss: 0.526966\n",
      "\n",
      "Test set: Average loss: 0.5095, Accuracy: 8453/10000 (85%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.731088\n",
      "Train Epoch: 47 [32000/60000 (53%)]\tLoss: 0.726446\n",
      "\n",
      "Test set: Average loss: 0.3008, Accuracy: 9097/10000 (91%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.519953\n",
      "Train Epoch: 48 [32000/60000 (53%)]\tLoss: 0.554675\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-323f92df01e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-ece872082516>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def visualize_stn():\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(test_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.stn(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2,figsize=(20,20))\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Transformed Images')\n",
    "\n",
    "for epoch in range(1, 100 + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "# Visualize the STN transformation on some input batch\n",
    "visualize_stn()\n",
    "wandb.log({'Final':wandb.Image(visualize_stn)})\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
