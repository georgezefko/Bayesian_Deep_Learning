{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fb43e184d60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "import wandb\n",
    "from src.data import make_dataset\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzefko\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/zefko/Bayesian%20DL/runs/tsh8lx5m\" target=\"_blank\">STN_trial</a></strong> to <a href=\"https://wandb.ai/zefko/Bayesian%20DL\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/zefko/Bayesian%20DL/runs/tsh8lx5m?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4addd62350>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Bayesian DL\", name = 'STN_trial', entity=\"zefko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"kernel_size\": 5,\n",
    "    \"channels\":1,\n",
    "    \"filter_1_out\" :16,\n",
    "    \"filter_2_out\" :32,\n",
    "    \"padding\" :0,\n",
    "    \"stride\" :1, \n",
    "    \"pool\":2,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64,\n",
    "    \"crop_size\":128\n",
    "}\n",
    "\n",
    "\n",
    "wandb.config ={\n",
    "    \n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n",
      "0.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader,test_loader = make_dataset.data(config[\"batch_size\"],config[\"crop_size\"],misplacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 4\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[1].squeeze()\n",
    "label = train_labels[1]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_dt = wandb.Table(columns=[\"id\", \"image\", \"label\", \"split\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    label = train_labels[i]\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(train_features[i][0], cmap='gray')\n",
    "    plt.title(label)\n",
    "    #print(f\"Label: {label}\")\n",
    "    preview_dt.add_data(i,wandb.Image(train_features[i]),label,'train')\n",
    "wandb.log({'Train Input':preview_dt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #self.conv3 = nn.Conv2d(20, 30, kernel_size=5)\n",
    "        #self.conv3_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50) #original\n",
    "        #self.fc1 = nn.Linear(16820, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "#apply laplace to the last linera layer for the first attempt\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),#original\n",
    "            #nn.Linear(10 * 28* 28, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        #print('x',x.size())\n",
    "        xs = self.localization(x)\n",
    "\n",
    "        #print('xs',xs.size())\n",
    "        xs = xs.view(-1, 10 * 3 * 3) #original\n",
    "        #xs = xs.view(-1, 10 * 28 * 28)\n",
    "\n",
    "        #print('xs view',xs.size())\n",
    "        theta = self.fc_loc(xs)\n",
    "\n",
    "        #print('theta before view',theta.shape)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        #print('theta',theta.shape)\n",
    "        #print('size',x.size())\n",
    "\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size(),align_corners =True)\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #print('input',x.size())\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        #print('transform',x.size())\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        #print('forward1',x.size())\n",
    "\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #print('forward2',x.size())\n",
    "\n",
    "        #x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
    "        #print('forward2+',x.size())\n",
    "\n",
    "        x = x.view(-1, 320) #original\n",
    "        #x = x.view(-1, 16820)\n",
    "\n",
    "        #print('forward3',x.size())\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print('forward4',x.size())\n",
    "\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        #print('forward5',x.size())\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        #print('forward6',x.size())\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    wandb.watch(model, optimizer,log=\"all\", log_freq=10)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            wandb.log({\"epoch\": epoch, \"loss\": loss.item()})\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        wandb.log({\"test loss\": test_loss})\n",
    "\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_np(inp):\n",
    "    \"\"\"Convert a Tensor to numpy image.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:4004: UserWarning:\n",
      "\n",
      "Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306885\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.307741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning:\n",
      "\n",
      "size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2997, Accuracy: 1439/10000 (14%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.299720\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.300446\n",
      "\n",
      "Test set: Average loss: 2.2913, Accuracy: 1561/10000 (16%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.287234\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.284089\n",
      "\n",
      "Test set: Average loss: 2.2578, Accuracy: 1782/10000 (18%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.268181\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.228454\n",
      "\n",
      "Test set: Average loss: 2.1956, Accuracy: 1947/10000 (19%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.133359\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.169870\n",
      "\n",
      "Test set: Average loss: 2.1461, Accuracy: 2096/10000 (21%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.171651\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.113768\n",
      "\n",
      "Test set: Average loss: 2.0961, Accuracy: 2198/10000 (22%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.104756\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.045749\n",
      "\n",
      "Test set: Average loss: 2.0208, Accuracy: 2375/10000 (24%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.102748\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.017626\n",
      "\n",
      "Test set: Average loss: 1.9810, Accuracy: 2361/10000 (24%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.080063\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.186505\n",
      "\n",
      "Test set: Average loss: 1.9312, Accuracy: 2613/10000 (26%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.993711\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.048718\n",
      "\n",
      "Test set: Average loss: 1.8411, Accuracy: 2989/10000 (30%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 1.976205\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 1.714423\n",
      "\n",
      "Test set: Average loss: 1.7486, Accuracy: 3331/10000 (33%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 1.905603\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 1.944880\n",
      "\n",
      "Test set: Average loss: 1.6445, Accuracy: 3552/10000 (36%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 1.814698\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 1.643364\n",
      "\n",
      "Test set: Average loss: 1.5758, Accuracy: 3780/10000 (38%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 1.514639\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 1.606167\n",
      "\n",
      "Test set: Average loss: 1.5995, Accuracy: 3953/10000 (40%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 1.786065\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 1.709171\n",
      "\n",
      "Test set: Average loss: 1.4081, Accuracy: 5108/10000 (51%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 1.618745\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 1.436280\n",
      "\n",
      "Test set: Average loss: 1.2931, Accuracy: 5564/10000 (56%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 1.342830\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 1.393764\n",
      "\n",
      "Test set: Average loss: 1.3461, Accuracy: 5447/10000 (54%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 1.681072\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 1.107394\n",
      "\n",
      "Test set: Average loss: 1.0149, Accuracy: 6723/10000 (67%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 1.148275\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 1.093628\n",
      "\n",
      "Test set: Average loss: 0.8375, Accuracy: 7512/10000 (75%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 1.064854\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.867631\n",
      "\n",
      "Test set: Average loss: 0.7491, Accuracy: 7709/10000 (77%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 1.032625\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 1.043231\n",
      "\n",
      "Test set: Average loss: 0.6584, Accuracy: 7961/10000 (80%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 1.363205\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.659405\n",
      "\n",
      "Test set: Average loss: 0.8295, Accuracy: 7312/10000 (73%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 1.424728\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.865257\n",
      "\n",
      "Test set: Average loss: 0.4721, Accuracy: 8681/10000 (87%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.742816\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.904777\n",
      "\n",
      "Test set: Average loss: 0.4201, Accuracy: 8790/10000 (88%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.431579\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.565528\n",
      "\n",
      "Test set: Average loss: 0.5111, Accuracy: 8497/10000 (85%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.707189\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 0.530510\n",
      "\n",
      "Test set: Average loss: 0.4548, Accuracy: 8760/10000 (88%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.604260\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 1.004811\n",
      "\n",
      "Test set: Average loss: 0.4176, Accuracy: 8811/10000 (88%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.554169\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 0.736967\n",
      "\n",
      "Test set: Average loss: 0.5585, Accuracy: 8314/10000 (83%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.772247\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 0.578643\n",
      "\n",
      "Test set: Average loss: 0.4946, Accuracy: 8487/10000 (85%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.782214\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 0.989217\n",
      "\n",
      "Test set: Average loss: 0.5422, Accuracy: 8285/10000 (83%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 1.037729\n",
      "Train Epoch: 31 [32000/60000 (53%)]\tLoss: 0.510116\n",
      "\n",
      "Test set: Average loss: 0.4360, Accuracy: 8696/10000 (87%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 1.187025\n",
      "Train Epoch: 32 [32000/60000 (53%)]\tLoss: 0.666798\n",
      "\n",
      "Test set: Average loss: 0.3433, Accuracy: 9012/10000 (90%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.628394\n",
      "Train Epoch: 33 [32000/60000 (53%)]\tLoss: 0.739571\n",
      "\n",
      "Test set: Average loss: 0.4323, Accuracy: 8665/10000 (87%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.525968\n",
      "Train Epoch: 34 [32000/60000 (53%)]\tLoss: 0.488148\n",
      "\n",
      "Test set: Average loss: 0.3386, Accuracy: 9057/10000 (91%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.641522\n",
      "Train Epoch: 35 [32000/60000 (53%)]\tLoss: 0.482309\n",
      "\n",
      "Test set: Average loss: 0.3051, Accuracy: 9100/10000 (91%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.570920\n",
      "Train Epoch: 36 [32000/60000 (53%)]\tLoss: 0.825839\n",
      "\n",
      "Test set: Average loss: 0.3042, Accuracy: 9139/10000 (91%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.569839\n",
      "Train Epoch: 37 [32000/60000 (53%)]\tLoss: 0.588277\n",
      "\n",
      "Test set: Average loss: 0.3006, Accuracy: 9147/10000 (91%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.663293\n",
      "Train Epoch: 38 [32000/60000 (53%)]\tLoss: 0.364121\n",
      "\n",
      "Test set: Average loss: 0.3185, Accuracy: 9059/10000 (91%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.569396\n",
      "Train Epoch: 39 [32000/60000 (53%)]\tLoss: 0.645748\n",
      "\n",
      "Test set: Average loss: 0.4481, Accuracy: 8712/10000 (87%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.701559\n",
      "Train Epoch: 40 [32000/60000 (53%)]\tLoss: 0.261595\n",
      "\n",
      "Test set: Average loss: 0.3201, Accuracy: 9120/10000 (91%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.482581\n",
      "Train Epoch: 41 [32000/60000 (53%)]\tLoss: 0.638463\n",
      "\n",
      "Test set: Average loss: 0.3407, Accuracy: 9031/10000 (90%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.631761\n",
      "Train Epoch: 42 [32000/60000 (53%)]\tLoss: 0.375874\n",
      "\n",
      "Test set: Average loss: 0.3481, Accuracy: 8958/10000 (90%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.646926\n",
      "Train Epoch: 43 [32000/60000 (53%)]\tLoss: 0.758654\n",
      "\n",
      "Test set: Average loss: 0.3182, Accuracy: 9105/10000 (91%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.414463\n",
      "Train Epoch: 44 [32000/60000 (53%)]\tLoss: 0.646148\n",
      "\n",
      "Test set: Average loss: 0.2501, Accuracy: 9280/10000 (93%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.565218\n",
      "Train Epoch: 45 [32000/60000 (53%)]\tLoss: 0.393873\n",
      "\n",
      "Test set: Average loss: 0.2420, Accuracy: 9292/10000 (93%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.456528\n",
      "Train Epoch: 46 [32000/60000 (53%)]\tLoss: 0.526966\n",
      "\n",
      "Test set: Average loss: 0.5095, Accuracy: 8453/10000 (85%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.731088\n",
      "Train Epoch: 47 [32000/60000 (53%)]\tLoss: 0.726446\n",
      "\n",
      "Test set: Average loss: 0.3008, Accuracy: 9097/10000 (91%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.519953\n",
      "Train Epoch: 48 [32000/60000 (53%)]\tLoss: 0.554675\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-323f92df01e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-ece872082516>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def visualize_stn():\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(test_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.stn(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2,figsize=(20,20))\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Transformed Images')\n",
    "\n",
    "for epoch in range(1, 100 + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "# Visualize the STN transformation on some input batch\n",
    "visualize_stn()\n",
    "wandb.log({'Final':wandb.Image(visualize_stn)})\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
