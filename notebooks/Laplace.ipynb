{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplace.baselaplace import FullLaplace\n",
    "from laplace.curvature.backpack import BackPackGGN\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from laplace import Laplace, marglik_training\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/georgioszefkilis/Bayesian_Deep_Learning/models/best_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"kernel_size\": 5,\n",
    "    \"channels\":1,\n",
    "    \"filter_1_out\" :16,\n",
    "    \"filter_2_out\" :32,\n",
    "    \"padding\" :0,\n",
    "    \"stride\" :1, \n",
    "    \"pool\":2,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64,\n",
    "    \"crop_size\":128\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_conv_dim(dim_size, kernel_size, padding, stride):\n",
    "  # (I-F)+2*P/S +1\n",
    "    return int((dim_size - kernel_size + 2 * padding) / stride + 1)\n",
    "\n",
    "def compute_pool_dim(dim_size, kernel_size, stride):\n",
    "  #(I-F)/S +1\n",
    "  return int((dim_size - kernel_size) / stride + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib import polynomial\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(config[\"channels\"], config[\"filter_1_out\"], config[\"kernel_size\"])\n",
    "        #evaluating image dimensions after first connvolution\n",
    "        self.conv1_out_height = compute_conv_dim(28, config[\"kernel_size\"], config[\"padding\"], config[\"stride\"])\n",
    "        self.conv1_out_width = compute_conv_dim(28,  config[\"kernel_size\"],  config[\"padding\"],  config[\"stride\"])\n",
    "\n",
    "\n",
    "        #first pooling\n",
    "        self.pool1 = nn.MaxPool2d(config[\"pool\"], config[\"pool\"])\n",
    "        #evaluating image dimensions after first pooling\n",
    "        self.conv2_out_height = compute_pool_dim(self.conv1_out_height, config[\"pool\"], config[\"pool\"])\n",
    "        self.conv2_out_width = compute_pool_dim(self.conv1_out_width,  config[\"pool\"],  config[\"pool\"])\n",
    "        \n",
    "        \n",
    "        #Second Convolution\n",
    "        self.conv2 = nn.Conv2d(config[\"filter_1_out\"], config[\"filter_2_out\"], config[\"kernel_size\"])\n",
    "        #evaluating image dimensions after second convolution\n",
    "        self.conv3_out_height = compute_conv_dim(self.conv2_out_height, config[\"kernel_size\"], config[\"padding\"], config[\"stride\"])\n",
    "        self.conv3_out_width = compute_conv_dim(self.conv2_out_width,  config[\"kernel_size\"], config[\"padding\"], config[\"stride\"])\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "\n",
    "        \n",
    "        #Second pooling\n",
    "        self.pool2 = nn.MaxPool2d(config[\"pool\"], config[\"pool\"])\n",
    "        #evaluating image dimensions after second pooling\n",
    "        self.conv4_out_height = compute_pool_dim(self.conv3_out_height, config[\"pool\"], config[\"pool\"])\n",
    "        self.conv4_out_width = compute_pool_dim(self.conv3_out_width,  config[\"pool\"], config[\"pool\"])\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(config[\"filter_2_out\"]* self.conv4_out_height * self.conv4_out_width, 50)\n",
    "        #print(self.fc1)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "#apply laplace to the last linera layer for the first attempt\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),#original\n",
    "            #nn.Linear(10 * 28* 28, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        #print('x',x.size())\n",
    "        xs = self.localization(x)\n",
    "\n",
    "        #print('xs',xs.size())\n",
    "        xs = xs.view(-1, 10 * 3 * 3) #original\n",
    "        #xs = xs.view(-1, xs.size(0))\n",
    "\n",
    "        #print('xs view',xs.size())\n",
    "        theta = self.fc_loc(xs)\n",
    "\n",
    "        #print('theta before view',theta.shape)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        #print('theta',theta.shape)\n",
    "        #print('size',x.size())\n",
    "\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size(),align_corners =True)\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #print('input',x.size())\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        #print('transform',x.size())\n",
    "        # Perform the usual forward pass\n",
    "        #convolutional layer 1\n",
    "        x = F.relu(self.pool1(self.conv1(x)))\n",
    "        #print('forward1',x.size())\n",
    "\n",
    "        #convolutional layer 2\n",
    "        x = F.relu(self.pool2(self.conv2_drop(self.conv2(x))))\n",
    "        #print('forward2',x.size())\n",
    "\n",
    "        #convolutional layer 3\n",
    "        #x = F.relu(self.pool3(self.conv3_drop(self.conv3(x))))\n",
    "        #print('forward3',x.size())\n",
    "\n",
    "        #x = x.view(-1, 320) #original\n",
    "        #print(self.conv3_out_height)\n",
    "        #print(self.conv4_out_width)\n",
    "        x = x.view(-1, config[\"filter_2_out\"]* self.conv4_out_height * self.conv4_out_width)\n",
    "\n",
    "        #print('flatten',x.size())\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print('forward4',x.size())\n",
    "\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        #print('forward5',x.size())\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        #print('forward6',x.size())\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath,map_location=device)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = True\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = load_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=512, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(model_path,map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=512, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (localization): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc_loc): Sequential(\n",
       "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(root='.', train=True, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])), batch_size=config[\"batch_size\"], shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(root='.', train=False, transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), batch_size=config[\"batch_size\"], shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.cat([y for x, y in test_loader], dim=0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(dataloader, model, laplace=False):\n",
    "    py = []\n",
    "\n",
    "    for x, _ in dataloader:\n",
    "        if laplace:\n",
    "            py.append(model(x))\n",
    "        else:\n",
    "            py.append(torch.softmax(model(x), dim=-1))\n",
    "\n",
    "    return torch.cat(py).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgioszefkilis/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/nn/functional.py:4003: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "probs_map = predict(test_loader, model_load, laplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.18608527e-16, 1.28331623e-10, 1.26332495e-12, ...,\n",
       "        1.17467425e-09, 2.65577421e-11, 4.58735556e-08],\n",
       "       [2.97033861e-16, 3.29422600e-11, 1.25809736e-12, ...,\n",
       "        5.78506854e-10, 5.44891779e-12, 3.53229179e-09],\n",
       "       [1.00000000e+00, 1.61064619e-14, 3.30366916e-08, ...,\n",
       "        1.13900195e-10, 5.40308388e-11, 1.88025498e-10],\n",
       "       ...,\n",
       "       [1.99723682e-10, 9.99999166e-01, 6.77935304e-07, ...,\n",
       "        1.36583381e-07, 3.01092129e-08, 4.78407491e-09],\n",
       "       [1.89883238e-08, 9.99910593e-01, 5.15634456e-05, ...,\n",
       "        3.60269297e-07, 1.10769488e-05, 5.13353768e-07],\n",
       "       [6.35115853e-08, 1.53136934e-10, 3.72874648e-10, ...,\n",
       "        1.44481188e-13, 1.52956403e-08, 1.15241983e-11]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_map = (probs_map.argmax(-1) == targets).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1028"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_prob = torch.from_numpy(probs_map)\n",
    "torch_target = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_map = -dists.Categorical(torch_prob).log_prob(torch_target).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.0784)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAP] Acc.: 10.3%; NLL: 13.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'[MAP] Acc.: {acc_map:.1%}; NLL: {nll_map:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "BackPACK extension expects a backpropagation quantity but it is None. Module: Linear(in_features=50, out_features=10, bias=True), Extension: <backpack.extensions.secondorder.hbp.KFLR object at 0x7f9a07fed0d0>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/georgioszefkilis/Bayesian_Deep_Learning/notebooks/Laplace.ipynb Cell 27'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgioszefkilis/Bayesian_Deep_Learning/notebooks/Laplace.ipynb#ch0000024?line=0'>1</a>\u001b[0m la \u001b[39m=\u001b[39m Laplace(model_load, \u001b[39m'\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgioszefkilis/Bayesian_Deep_Learning/notebooks/Laplace.ipynb#ch0000024?line=1'>2</a>\u001b[0m              subset_of_weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlast_layer\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgioszefkilis/Bayesian_Deep_Learning/notebooks/Laplace.ipynb#ch0000024?line=2'>3</a>\u001b[0m              hessian_structure\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mkron\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/georgioszefkilis/Bayesian_Deep_Learning/notebooks/Laplace.ipynb#ch0000024?line=3'>4</a>\u001b[0m la\u001b[39m.\u001b[39;49mfit(train_loader)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/georgioszefkilis/Bayesian_Deep_Learning/notebooks/Laplace.ipynb#ch0000024?line=4'>5</a>\u001b[0m la\u001b[39m.\u001b[39moptimize_prior_precision(method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmarglik\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/lllaplace.py:114\u001b[0m, in \u001b[0;36mLLLaplace.fit\u001b[0;34m(self, train_loader, override)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/lllaplace.py?line=110'>111</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprior_mean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prior_mean\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/lllaplace.py?line=111'>112</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_H()\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/lllaplace.py?line=113'>114</a>\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(train_loader, override\u001b[39m=\u001b[39;49moverride)\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/lllaplace.py?line=114'>115</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean \u001b[39m=\u001b[39m parameters_to_vector(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mlast_layer\u001b[39m.\u001b[39mparameters())\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py:797\u001b[0m, in \u001b[0;36mKronLaplace.fit\u001b[0;34m(self, train_loader, override)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=793'>794</a>\u001b[0m     \u001b[39m# discount previous Kronecker factors to sum up properly together with new ones\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=794'>795</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_facs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rescale_factors(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_facs, n_data_old \u001b[39m/\u001b[39m (n_data_old \u001b[39m+\u001b[39m n_data_new))\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=796'>797</a>\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(train_loader, override\u001b[39m=\u001b[39;49moverride)\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=798'>799</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_facs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=799'>800</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH_facs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py:377\u001b[0m, in \u001b[0;36mParametricLaplace.fit\u001b[0;34m(self, train_loader, override)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=374'>375</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=375'>376</a>\u001b[0m X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device), y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device)\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=376'>377</a>\u001b[0m loss_batch, H_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_curv_closure(X, y, N)\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=377'>378</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_batch\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=378'>379</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m H_batch\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py:777\u001b[0m, in \u001b[0;36mKronLaplace._curv_closure\u001b[0;34m(self, X, y, N)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=775'>776</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_curv_closure\u001b[39m(\u001b[39mself\u001b[39m, X, y, N):\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/baselaplace.py?line=776'>777</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackend\u001b[39m.\u001b[39;49mkron(X, y, N\u001b[39m=\u001b[39;49mN)\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/curvature/backpack.py:134\u001b[0m, in \u001b[0;36mBackPackGGN.kron\u001b[0;34m(self, X, y, N, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/curvature/backpack.py?line=131'>132</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlossfunc(f, y)\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/curvature/backpack.py?line=132'>133</a>\u001b[0m \u001b[39mwith\u001b[39;00m backpack(context()):\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/curvature/backpack.py?line=133'>134</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/curvature/backpack.py?line=134'>135</a>\u001b[0m kron \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_kron_factors()\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/laplace/curvature/backpack.py?line=135'>136</a>\u001b[0m kron \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rescale_kron_factors(kron, \u001b[39mlen\u001b[39m(y), N)\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py:110\u001b[0m, in \u001b[0;36mBackwardHook._set_user_hook.<locals>.hook\u001b[0;34m(grad_input, _)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=101'>102</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mModule backward hook for grad_input is called before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=102'>103</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mthe grad_output one. This happens because the gradient \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=103'>104</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39min your nn.Module flows to the Module\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms input without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=104'>105</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mpassing through the Module\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms output. Make sure that the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=105'>106</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39moutput depends on the input and that the loss is computed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=106'>107</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mbased on the output.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=108'>109</a>\u001b[0m grad_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pack_with_none(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_tensors_index, grad_input, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_inputs)\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=109'>110</a>\u001b[0m res \u001b[39m=\u001b[39m user_hook(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule, grad_input, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrad_outputs)\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=110'>111</a>\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/torch/utils/hooks.py?line=111'>112</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/__init__.py:209\u001b[0m, in \u001b[0;36mhook_run_extensions\u001b[0;34m(module, g_inp, g_out)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/__init__.py?line=206'>207</a>\u001b[0m     \u001b[39mif\u001b[39;00m debug:\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/__init__.py?line=207'>208</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[DEBUG] Running extension\u001b[39m\u001b[39m\"\u001b[39m, backpack_extension, \u001b[39m\"\u001b[39m\u001b[39mon\u001b[39m\u001b[39m\"\u001b[39m, module)\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/__init__.py?line=208'>209</a>\u001b[0m     backpack_extension(module, g_inp, g_out)\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/__init__.py?line=210'>211</a>\u001b[0m \u001b[39mif\u001b[39;00m debug:\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/__init__.py?line=211'>212</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[DEBUG] Running extension hook on\u001b[39m\u001b[39m\"\u001b[39m, module)\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/backprop_extension.py:127\u001b[0m, in \u001b[0;36mBackpropExtension.__call__\u001b[0;34m(self, module, g_inp, g_out)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/backprop_extension.py?line=124'>125</a>\u001b[0m module_extension \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_module_extension(module)\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/backprop_extension.py?line=125'>126</a>\u001b[0m \u001b[39mif\u001b[39;00m module_extension \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/backprop_extension.py?line=126'>127</a>\u001b[0m     module_extension(\u001b[39mself\u001b[39;49m, module, g_inp, g_out)\n",
      "File \u001b[0;32m~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py:106\u001b[0m, in \u001b[0;36mModuleExtension.__call__\u001b[0;34m(self, extension, module, g_inp, g_out)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=97'>98</a>\u001b[0m bp_quantity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_backproped_quantity(\n\u001b[1;32m     <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=98'>99</a>\u001b[0m     extension, module\u001b[39m.\u001b[39moutput, delete_old_quantities\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=99'>100</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=100'>101</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=101'>102</a>\u001b[0m     extension\u001b[39m.\u001b[39mexpects_backpropagation_quantities()\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=102'>103</a>\u001b[0m     \u001b[39mand\u001b[39;00m bp_quantity \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=103'>104</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_loss(module)\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=104'>105</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=105'>106</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=106'>107</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBackPACK extension expects a backpropagation quantity but it is None. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=107'>108</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule: \u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m}\u001b[39;00m\u001b[39m, Extension: \u001b[39m\u001b[39m{\u001b[39;00mextension\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=108'>109</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=110'>111</a>\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__params:\n\u001b[1;32m    <a href='file:///~/anaconda3/anaconda3/envs/Bayesian_DL/lib/python3.8/site-packages/backpack/extensions/module_extension.py?line=111'>112</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__param_exists_and_requires_grad(module, param):\n",
      "\u001b[0;31mAssertionError\u001b[0m: BackPACK extension expects a backpropagation quantity but it is None. Module: Linear(in_features=50, out_features=10, bias=True), Extension: <backpack.extensions.secondorder.hbp.KFLR object at 0x7f9a07fed0d0>."
     ]
    }
   ],
   "source": [
    "la = Laplace(model_load, 'classification',\n",
    "             subset_of_weights='last_layer',\n",
    "             hessian_structure='kron')\n",
    "la.fit(train_loader)\n",
    "la.optimize_prior_precision(method='marglik')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5519e73fd253ddc2638f9eb90f462b822a94835075ef16496d7f936ba3e281cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Bayesian_DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
