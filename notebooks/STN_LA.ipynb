{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fe344de6fa0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "\n",
    "#laplace packages\n",
    "from laplace.baselaplace import FullLaplace\n",
    "from laplace.curvature.backpack import BackPackGGN\n",
    "from laplace import Laplace, marglik_training\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzefko\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/zefko/Bayesian%20DL/runs/2nrrrrvv\" target=\"_blank\">STN_LA_version_1</a></strong> to <a href=\"https://wandb.ai/zefko/Bayesian%20DL\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/zefko/Bayesian%20DL/runs/2nrrrrvv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe34badf940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Bayesian DL\", name = 'STN_LA_version_1', entity=\"zefko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistRandomPlacement(Dataset):\n",
    "\n",
    "  def __init__(self, crop_size, digits,mode,download=True):\n",
    "\n",
    "    self.datasets = []\n",
    "    self.cropsize = crop_size\n",
    "    self.download = download\n",
    "    self.digits = digits\n",
    "    self.mode = mode\n",
    "\n",
    "    # False (test) or True (train,val)\n",
    "    trainingset = self.mode in ['train', 'val']\n",
    "\n",
    "    self.datasets.append(datasets.MNIST('/content/',\n",
    "                        transform=transforms.Compose([\n",
    "                        transforms.ToTensor()]),\n",
    "                        train=trainingset,\n",
    "                        download=self.download))\n",
    "\n",
    "    # self.datasets.append(datasets.KMNIST(opt.dataroot,\n",
    "    #                     transform=transforms.Compose([\n",
    "    #                     transforms.ToTensor()]),\n",
    "    #                     train=trainingset,\n",
    "    #                     download=opt.download))\n",
    "\n",
    "    self.num_images = self.digits\n",
    "\n",
    "  def __len__(self):\n",
    "    return min([self.datasets[0].__len__() for i in range(self.num_images)])\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    im = torch.zeros((1, 96, 96), dtype=torch.float)\n",
    "\n",
    "    used_positions, target = [], ''\n",
    "    for i in range(self.num_images):\n",
    "      while True:\n",
    "        x = np.random.randint(0, 96 - 32)\n",
    "        if len(used_positions) == 0 or abs(used_positions[0][0] - x) > 32:\n",
    "          break\n",
    "      while True:\n",
    "        y = np.random.randint(0, 96 - 32)\n",
    "        if len(used_positions) == 0 or abs(used_positions[0][1] - y) > 32:\n",
    "          break\n",
    "\n",
    "      im1, target1 = self.datasets[i].__getitem__((idx) * (i + 1) % self.datasets[i].__len__())\n",
    "\n",
    "      c, w, h = im1.shape\n",
    "\n",
    "      im[:, y:y + h, x:x + w] = im1.type(torch.float)\n",
    "      #print('created image', im.shape, 'x:', x, 'y:', y)\n",
    "\n",
    "      target += str(target1)\n",
    "\n",
    "      transform = transforms.Compose(\n",
    "      [transforms.ToPILImage(),transforms.Resize(self.cropsize), transforms.ToTensor(),#, transforms.RandomRotation(degrees=(0,180))\n",
    "      transforms.Normalize((0.1307,), (0.3081,))])\n",
    "      im = transform(im)\n",
    "\n",
    "      \n",
    "\n",
    "      return im,int(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"kernel_size\": 5,\n",
    "    \"channels\":1,\n",
    "    \"filter_1_out\" :16,\n",
    "    \"filter_2_out\" :32,\n",
    "    \"padding\" :0,\n",
    "    \"stride\" :1, \n",
    "    \"pool\":2,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64,\n",
    "    \"crop_size\":128\n",
    "}\n",
    "\n",
    "\n",
    "wandb.config ={\n",
    "    \n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mnist = MnistRandomPlacement(config[\"crop_size\"],10,'train',True)\n",
    "test_mnist = MnistRandomPlacement(config[\"crop_size\"],10,'test',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(train_mnist.datasets[0])):\n",
    "    image,label = train_mnist[i]\n",
    "\n",
    "    print(i, image.shape, label)\n",
    "\n",
    "    ax = plt.subplot(1, 5, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    ax.imshow(image[0,:,:].numpy())\n",
    "\n",
    "    if i == 4:\n",
    "        plt.show()\n",
    "        break\n",
    "wandb.log({'MNIST examples': wandb.Image(fig)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def data(misplacement=True):\n",
    "\n",
    "    if misplacement:\n",
    "        train_mnist = MnistRandomPlacement(config[\"crop_size\"],10,'train',True)\n",
    "        test_mnist = MnistRandomPlacement(config[\"crop_size\"],10,'test',True)\n",
    "        train_loader = torch.utils.data.DataLoader(train_mnist, batch_size=64, shuffle=True, num_workers=2)\n",
    "        test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "    else:\n",
    "    #Training dataset\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(root='.', train=True, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])), batch_size=config[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "\n",
    "        #Test dataset\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(root='.', train=False, transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), batch_size=config[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "    return train_loader,test_loader\n",
    "\n",
    "\n",
    "train_loader,test_loader = data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[1].squeeze()\n",
    "label = train_labels[1]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_dt = wandb.Table(columns=[\"id\", \"image\", \"label\", \"split\"])\n",
    "\n",
    "for i in range(10):\n",
    "    label = train_labels[i]\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(train_features[i][0], cmap='gray')\n",
    "    plt.title(label)\n",
    "    #print(f\"Label: {label}\")\n",
    "    preview_dt.add_data(i,wandb.Image(train_features[i]),label,'train')\n",
    "wandb.log({'Train Input':preview_dt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "height =train_features.shape[2]\n",
    "width= train_features.shape[3]\n",
    "\n",
    "def compute_conv_dim(dim_size, kernel_size, padding, stride):\n",
    "  # (I-F)+2*P/S +1\n",
    "    return int((dim_size - kernel_size + 2 * padding) / stride + 1)\n",
    "\n",
    "def compute_pool_dim(dim_size, kernel_size, stride):\n",
    "  #(I-F)/S +1\n",
    "  return int((dim_size - kernel_size) / stride + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib import polynomial\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(config[\"channels\"], config[\"filter_1_out\"], config[\"kernel_size\"])\n",
    "        #evaluating image dimensions after first connvolution\n",
    "        self.conv1_out_height = compute_conv_dim(height, config[\"kernel_size\"], config[\"padding\"], config[\"stride\"])\n",
    "        self.conv1_out_width = compute_conv_dim(width,  config[\"kernel_size\"],  config[\"padding\"],  config[\"stride\"])\n",
    "\n",
    "\n",
    "        #first pooling\n",
    "        self.pool1 = nn.MaxPool2d(config[\"pool\"], config[\"pool\"])\n",
    "        #evaluating image dimensions after first pooling\n",
    "        self.conv2_out_height = compute_pool_dim(self.conv1_out_height, config[\"pool\"], config[\"pool\"])\n",
    "        self.conv2_out_width = compute_pool_dim(self.conv1_out_width,  config[\"pool\"],  config[\"pool\"])\n",
    "        \n",
    "        \n",
    "        #Second Convolution\n",
    "        self.conv2 = nn.Conv2d(config[\"filter_1_out\"], config[\"filter_2_out\"], config[\"kernel_size\"])\n",
    "        #evaluating image dimensions after second convolution\n",
    "        self.conv3_out_height = compute_conv_dim(self.conv2_out_height, config[\"kernel_size\"], config[\"padding\"], config[\"stride\"])\n",
    "        self.conv3_out_width = compute_conv_dim(self.conv2_out_width,  config[\"kernel_size\"], config[\"padding\"], config[\"stride\"])\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "\n",
    "        \n",
    "        #Second pooling\n",
    "        self.pool2 = nn.MaxPool2d(config[\"pool\"], config[\"pool\"])\n",
    "        #evaluating image dimensions after second pooling\n",
    "        self.conv4_out_height = compute_pool_dim(self.conv3_out_height, config[\"pool\"], config[\"pool\"])\n",
    "        self.conv4_out_width = compute_pool_dim(self.conv3_out_width,  config[\"pool\"], config[\"pool\"])\n",
    "        \n",
    "        #Third Convolution\n",
    "        # self.conv3 = nn.Conv2d(32, 64, kernel_size)\n",
    "        # #evaluating image dimensions after second convolution\n",
    "        # self.conv5_out_height = compute_conv_dim(self.conv4_out_height, kernel_size, padding,  stride)\n",
    "        # self.conv5_out_width = compute_conv_dim(self.conv4_out_width,  kernel_size,  padding,  stride)\n",
    "        # self.conv3_drop = nn.Dropout2d()\n",
    "\n",
    "        # #Second pooling\n",
    "        # self.pool3 = nn.MaxPool2d(pool, pool)\n",
    "        # #evaluating image dimensions after second pooling\n",
    "        # self.conv6_out_height = compute_pool_dim(self.conv5_out_height, pool, pool)\n",
    "        # self.conv6_out_width = compute_pool_dim(self.conv5_out_width,  pool, pool)\n",
    "        #print(self.conv4_out_height)\n",
    "        #print(self.conv4_out_width)\n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(config[\"filter_2_out\"]* self.conv4_out_height * self.conv4_out_width, 50)\n",
    "        #print(self.fc1)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "#apply laplace to the last linera layer for the first attempt\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            #nn.Linear(10 * 3 * 3, 32),#original\n",
    "            nn.Linear(10 * 28* 28, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        #print('x',x.size())\n",
    "        xs = self.localization(x)\n",
    "\n",
    "        #print('xs',xs.size())\n",
    "        #xs = xs.view(-1, 10 * 3 * 3) #original\n",
    "        xs = xs.view(-1, 10 * 28 * 28)\n",
    "\n",
    "        #print('xs view',xs.size())\n",
    "        theta = self.fc_loc(xs)\n",
    "\n",
    "        #print('theta before view',theta.shape)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        #print('theta',theta.shape)\n",
    "        #print('size',x.size())\n",
    "\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size(),align_corners =True)\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #print('input',x.size())\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        #print('transform',x.size())\n",
    "        # Perform the usual forward pass\n",
    "        #convolutional layer 1\n",
    "        x = F.relu(self.pool1(self.conv1(x)))\n",
    "        #print('forward1',x.size())\n",
    "\n",
    "        #convolutional layer 2\n",
    "        x = F.relu(self.pool2(self.conv2_drop(self.conv2(x))))\n",
    "        #print('forward2',x.size())\n",
    "\n",
    "        #convolutional layer 3\n",
    "        #x = F.relu(self.pool3(self.conv3_drop(self.conv3(x))))\n",
    "        #print('forward3',x.size())\n",
    "\n",
    "        #x = x.view(-1, 320) #original\n",
    "        #print(self.conv3_out_height)\n",
    "        #print(self.conv4_out_width)\n",
    "        x = x.view(-1, config[\"filter_2_out\"]* self.conv4_out_height * self.conv4_out_width)\n",
    "\n",
    "        #print('flatten',x.size())\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print('forward4',x.size())\n",
    "\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        #print('forward5',x.size())\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        #print('forward6',x.size())\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=config[\"learning_rate\"])\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    #wandb.watch(model, optimizer,log=\"all\", log_freq=10)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            wandb.log({\"epoch\": epoch, \"loss\": loss.item()})\n",
    "            #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "             #   epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "              #  100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        wandb.log({\"test loss\": test_loss,\n",
    "                    \"test_accuracy\":100. * correct / len(test_loader.dataset) })\n",
    "\n",
    "        #print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "         #     .format(test_loss, correct, len(test_loader.dataset),\n",
    "          #            100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_np(inp):\n",
    "    \"\"\"Convert a Tensor to numpy image.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_stn():\n",
    "\n",
    "     # create a wandb Artifact to version each test step separately\n",
    "    test_data_at = wandb.Artifact(\"test_samples_\" + str(wandb.run.id), type=\"predictions\")\n",
    "    # create a wandb.Table() in which to store predictions for each test step\n",
    "    columns=[ \"Grid in\", \"Grid out\"]\n",
    "    test_table = wandb.Table(columns=columns)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(test_loader))[0].to(device)\n",
    "        #for batch, (data,_) in enumerate(test_loader):\n",
    "          #data = data.to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.stn(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "        \n",
    "        # Plot the results side-by-side\n",
    "        test_table.add_data(wandb.Image(in_grid), wandb.Image(out_grid))\n",
    "    \n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2,figsize=(20,20))\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Transformed Images')\n",
    "        #f.suptitle(f'Bathc:{batch}') # or plt.suptitle('Main title')\n",
    "        \n",
    "    # log predictions table to wandb\n",
    "    test_data_at.add(test_table, \"predictions\")\n",
    "    wandb.run.log_artifact(test_data_at)\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, config[\"epochs\"]+ 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "# Visualize the STN transformation on some input batch\n",
    "visualize_stn()\n",
    "# #wandb.log({'Final':wandb.Image(visualize_stn)})\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da4a7da2390d72f3b1c06a5049815a34541045e97bdd62fd1e4143bbe5f97f5e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('my_environment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
